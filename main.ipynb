{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Swimming types classification"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version : 2.7.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn import metrics\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from shutil import copyfile, rmtree\n",
    "\n",
    "print('Tensorflow version : ' + tf.version.VERSION)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "CRAWL_SOURCE_DIR = os.path.join(os.getcwd(), 'data/train-val/crawl/')\n",
    "BREASTSTROKE_SOURCE_DIR = os.path.join(os.getcwd(), 'data/train-val/breaststroke/')\n",
    "BUTTERFLY_SOURCE_DIR = os.path.join(os.getcwd(), 'data/train-val/butterfly/')\n",
    "BACKSTROKE_SOURCE_DIR = os.path.join(os.getcwd(), 'data/train-val/backstroke/')\n",
    "TRAINING_DIR = os.path.join(os.getcwd(), 'tmp/swimming/training/')\n",
    "VALIDATION_DIR = os.path.join(os.getcwd(), 'tmp/swimming/validation/')\n",
    "IMAGE_TEST_FOLDER = os.path.join(os.getcwd(), 'data/test/')\n",
    "SPLIT_SIZE = .9\n",
    "USE_PRETRAINED_MODEL = False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data splitting"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "def split_data(source, name, split_size):\n",
    "\n",
    "    training_dir = TRAINING_DIR + name+'/'\n",
    "    validation_dir = VALIDATION_DIR + name+'/'\n",
    "\n",
    "    if os.path.exists(training_dir) and os.path.isdir(training_dir):\n",
    "        rmtree(training_dir)\n",
    "    if os.path.exists(validation_dir) and os.path.isdir(validation_dir):\n",
    "        rmtree(validation_dir)\n",
    "\n",
    "    if not os.path.exists(training_dir):\n",
    "        os.makedirs(training_dir)\n",
    "    if not os.path.exists(validation_dir):\n",
    "        os.makedirs(validation_dir)\n",
    "\n",
    "    files = []\n",
    "    for filename in os.listdir(source):\n",
    "        file = source + filename\n",
    "        if os.path.getsize(file) > 0:\n",
    "            files.append(filename)\n",
    "        else:\n",
    "            print(filename + \" is zero length, so ignoring.\")\n",
    "\n",
    "    training_length = int(len(files) * split_size)\n",
    "    validation_length = int(len(files) - training_length)\n",
    "    shuffled_set = random.sample(files, len(files))\n",
    "    training_set = shuffled_set[:training_length]\n",
    "    validation_set = shuffled_set[:validation_length]\n",
    "\n",
    "    for filename in training_set:\n",
    "        this_file = source + filename\n",
    "        destination = training_dir + filename\n",
    "        copyfile(this_file, destination)\n",
    "\n",
    "    for filename in validation_set:\n",
    "        this_file = source + filename\n",
    "        destination = validation_dir + filename\n",
    "        copyfile(this_file, destination)\n",
    "\n",
    "split_data(CRAWL_SOURCE_DIR, 'crawl', SPLIT_SIZE)\n",
    "split_data(BREASTSTROKE_SOURCE_DIR, 'breaststroke', SPLIT_SIZE)\n",
    "split_data(BUTTERFLY_SOURCE_DIR, 'butterfly', SPLIT_SIZE)\n",
    "split_data(BACKSTROKE_SOURCE_DIR, 'backstroke', SPLIT_SIZE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data preparation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 589 images belonging to 4 classes.\n",
      "Found 67 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dataGen = ImageDataGenerator(rescale=1./255.,\n",
    "                                   rotation_range=40,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True)\n",
    "\n",
    "validation_dataGen = ImageDataGenerator(rescale=1. / 255.)\n",
    "\n",
    "train_Generator = train_dataGen.flow_from_directory(TRAINING_DIR,\n",
    "                                                    batch_size=64,\n",
    "                                                    class_mode='categorical',\n",
    "                                                    target_size=(244, 244))\n",
    "\n",
    "validation_generator = validation_dataGen.flow_from_directory(VALIDATION_DIR,\n",
    "                                                                batch_size=64,\n",
    "                                                                class_mode='categorical',\n",
    "                                                                target_size=(244, 244),\n",
    "                                                                shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Make model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "class Model(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.base_model = VGG16(input_shape=(244, 244, 3), include_top=False, weights='imagenet')\n",
    "        self.flat = tf.keras.layers.Flatten()\n",
    "        self.dense_1 = tf.keras.layers.Dense(units=1024, activation='relu')\n",
    "        self.dense_2 = tf.keras.layers.Dense(units=1024, activation='relu')\n",
    "        self.dense_3 = tf.keras.layers.Dense(units=512, activation='relu')\n",
    "        self.classifier = tf.keras.layers.Dense(4, activation='softmax', name=\"classification\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.base_model(inputs)\n",
    "        x = self.flat(x)\n",
    "        x = self.dense_1(x)\n",
    "        x = self.dense_2(x)\n",
    "        x = self.dense_3(x)\n",
    "        return self.classifier(x)\n",
    "\n",
    "model = Model()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/mt/8ylvhgn115d9rqd2svz0lprw0000gn/T/ipykernel_12172/159587853.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     11\u001B[0m                   metrics=['acc'])\n\u001B[1;32m     12\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 13\u001B[0;31m     vgg_hist = model.fit(train_Generator,\n\u001B[0m\u001B[1;32m     14\u001B[0m                          \u001B[0mvalidation_data\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mvalidation_generator\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     15\u001B[0m                          \u001B[0mepochs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m250\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Develop/miniforge3/envs/SwimmingTypeClassification/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     62\u001B[0m     \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     63\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 64\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     65\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m  \u001B[0;31m# pylint: disable=broad-except\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     66\u001B[0m       \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Develop/miniforge3/envs/SwimmingTypeClassification/lib/python3.9/site-packages/keras/engine/training.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1164\u001B[0m          \u001B[0mtraining_utils\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mRespectCompiledTrainableState\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1165\u001B[0m       \u001B[0;31m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1166\u001B[0;31m       data_handler = data_adapter.get_data_handler(\n\u001B[0m\u001B[1;32m   1167\u001B[0m           \u001B[0mx\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1168\u001B[0m           \u001B[0my\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Develop/miniforge3/envs/SwimmingTypeClassification/lib/python3.9/site-packages/keras/engine/data_adapter.py\u001B[0m in \u001B[0;36mget_data_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m   1401\u001B[0m   \u001B[0;32mif\u001B[0m \u001B[0mgetattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"model\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"_cluster_coordinator\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1402\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0m_ClusterCoordinatorDataHandler\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1403\u001B[0;31m   \u001B[0;32mreturn\u001B[0m \u001B[0mDataHandler\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1404\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1405\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Develop/miniforge3/envs/SwimmingTypeClassification/lib/python3.9/site-packages/keras/engine/data_adapter.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001B[0m\n\u001B[1;32m   1168\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1169\u001B[0m     \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_current_step\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1170\u001B[0;31m     \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_step_increment\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_steps_per_execution\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnumpy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mitem\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1171\u001B[0m     \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_insufficient_data\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mFalse\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1172\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Develop/miniforge3/envs/SwimmingTypeClassification/lib/python3.9/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001B[0m in \u001B[0;36mnumpy\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    643\u001B[0m   \u001B[0;32mdef\u001B[0m \u001B[0mnumpy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    644\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mcontext\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexecuting_eagerly\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 645\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread_value\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnumpy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    646\u001B[0m     raise NotImplementedError(\n\u001B[1;32m    647\u001B[0m         \"numpy() is only available when eager execution is enabled.\")\n",
      "\u001B[0;32m~/Develop/miniforge3/envs/SwimmingTypeClassification/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001B[0m in \u001B[0;36mnumpy\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1147\u001B[0m     \"\"\"\n\u001B[1;32m   1148\u001B[0m     \u001B[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1149\u001B[0;31m     \u001B[0mmaybe_arr\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_numpy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# pylint: disable=protected-access\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1150\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mmaybe_arr\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcopy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmaybe_arr\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mndarray\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0mmaybe_arr\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1151\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Develop/miniforge3/envs/SwimmingTypeClassification/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001B[0m in \u001B[0;36m_numpy\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1113\u001B[0m   \u001B[0;32mdef\u001B[0m \u001B[0m_numpy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1114\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1115\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_numpy_internal\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1116\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0mcore\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m  \u001B[0;31m# pylint: disable=protected-access\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1117\u001B[0m       \u001B[0;32mraise\u001B[0m \u001B[0mcore\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_status_to_exception\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;32mNone\u001B[0m  \u001B[0;31m# pylint: disable=protected-access\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "if not USE_PRETRAINED_MODEL:\n",
    "    callback_early_stopping = tf.keras.callbacks.EarlyStopping(monitor='loss',\n",
    "                                                               patience=10,\n",
    "                                                               verbose=1,\n",
    "                                                               mode='auto',\n",
    "                                                               baseline=None,\n",
    "                                                               restore_best_weights=True)\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=1e-3),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['acc'])\n",
    "\n",
    "    vgg_hist = model.fit(train_Generator,\n",
    "                         validation_data=validation_generator,\n",
    "                         epochs=250,\n",
    "                         callbacks=[callback_early_stopping])\n",
    "\n",
    "    model.save_weights('net.h5')\n",
    "else:\n",
    "    model.build((None,) + train_Generator.image_shape)\n",
    "    model.load_weights('net.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Plot metrics"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_metrics(hist, metrics, title):\n",
    "    plt.plot(hist.history[metrics])\n",
    "    plt.plot(hist.history['val_'+metrics])\n",
    "    plt.title(title)\n",
    "    plt.ylabel(metrics)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "if not USE_PRETRAINED_MODEL:\n",
    "    plot_metrics(vgg_hist, 'acc', 'Model accuracy')\n",
    "    plot_metrics(vgg_hist, 'loss', 'Model Loss')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "# Get the confusion matrix\n",
    "Y_pred = model.predict(validation_generator, verbose = True)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "confusion = metrics.confusion_matrix(validation_generator.classes, y_pred)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(confusion, classes=train_Generator.class_indices, title='Confusion matrix')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Testing model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "image_test_names = [_ for _ in os.listdir(IMAGE_TEST_FOLDER)]\n",
    "reverse_class_indices = {value : key for (key, value) in train_Generator.class_indices.items()}\n",
    "\n",
    "plt.figure(figsize=(20, 7))\n",
    "for index in range(len(image_test_names)):\n",
    "    img = image.load_img(IMAGE_TEST_FOLDER + image_test_names[index], target_size=(244, 244))\n",
    "    array_image = image.img_to_array(img)\n",
    "    array_image = np.expand_dims(array_image, axis=0)\n",
    "    array_image = array_image / 255.\n",
    "\n",
    "    image_tensor = np.vstack([array_image])\n",
    "    results = model.predict(image_tensor)\n",
    "    predict = np.argmax(results, axis = 1)\n",
    "\n",
    "    plt.subplot(2, 6, index + 1)\n",
    "    plt.title(reverse_class_indices.get(predict[0]), fontsize=15)\n",
    "    plt.imshow(img)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}